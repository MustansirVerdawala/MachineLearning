{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eQCDbLEHJY4V"
      },
      "outputs": [],
      "source": [
        "# =============================================================== #\n",
        "#                     2D Cell Segmenatation                       #\n",
        "#                      Mustansir Verdawala                        #\n",
        "# =============================================================== #"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#%% Installing libraries\n",
        "\n",
        "!pip install monai[itk] itk matplotlib torch torchvision torchaudio nibabel pydicom"
      ],
      "metadata": {
        "id": "kucWtixjJm2Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#%% Download Dataset\n",
        "\n",
        "!mkdir -p data/train data/masks/train\n",
        "!mkdir -p data/val data/masks/val\n",
        "!mkdir -p data/test data/masks/test\n",
        "\n",
        "!wget -O data/train.zip \"https://huggingface.co/datasets/alkzar90/cell_benchmark/resolve/main/data/train.zip\"\n",
        "!wget -O data/masks/train.zip \"https://huggingface.co/datasets/alkzar90/cell_benchmark/resolve/main/data/masks/train.zip\"\n",
        "!wget -O data/val.zip \"https://huggingface.co/datasets/alkzar90/cell_benchmark/resolve/main/data/val.zip\"\n",
        "!wget -O data/masks/val.zip \"https://huggingface.co/datasets/alkzar90/cell_benchmark/resolve/main/data/masks/val.zip\"\n",
        "!wget -O data/test.zip \"https://huggingface.co/datasets/alkzar90/cell_benchmark/resolve/main/data/test.zip\"\n",
        "!wget -O data/masks/test.zip \"https://huggingface.co/datasets/alkzar90/cell_benchmark/resolve/main/data/masks/test.zip\"\n",
        "\n",
        "!unzip -q data/train.zip -d data/train\n",
        "!unzip -q data/masks/train.zip -d data/masks/train\n",
        "!unzip -q data/val.zip -d data/val\n",
        "!unzip -q data/masks/val.zip -d data/masks/val\n",
        "!unzip -q data/test.zip -d data/test\n",
        "!unzip -q data/masks/test.zip -d data/masks/test"
      ],
      "metadata": {
        "id": "umPOCoODJohc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#%% Viewing dataset\n",
        "\n",
        "import os\n",
        "\n",
        "train_images_dir = \"data/train/train\"\n",
        "train_masks_dir = \"data/masks/train\"\n",
        "val_images_dir = \"data/val/val\"\n",
        "val_masks_dir = \"data/masks/val\"\n",
        "test_images_dir = \"data/test/test\"\n",
        "test_masks_dir = \"data/masks/test\"\n",
        "\n",
        "print(\"Train Images:\", os.listdir(train_images_dir))\n",
        "print(\"Train Masks:\", os.listdir(train_masks_dir))\n",
        "print(\"Validation Images:\", os.listdir(val_images_dir))\n",
        "print(\"Validation Masks:\", os.listdir(val_masks_dir))\n",
        "print(\"Test Images:\", os.listdir(test_images_dir))\n",
        "print(\"Test Masks:\", os.listdir(test_masks_dir))"
      ],
      "metadata": {
        "id": "onQx48WWJqB6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#%% Previewing image\n",
        "\n",
        "import itk\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from pathlib import Path\n",
        "\n",
        "img_dir = Path(\"data/train/train\")\n",
        "mask_dir = Path(\"data/masks/train\")\n",
        "\n",
        "img_files = sorted(img_dir.glob(\"*.jpg\"))\n",
        "mask_files = sorted(mask_dir.glob(\"*.png\"))\n",
        "\n",
        "img_itk = itk.imread(str(img_files[0]), itk.RGBPixel[itk.UC])\n",
        "mask_itk = itk.imread(str(mask_files[0]), itk.UC)\n",
        "\n",
        "img_np = itk.array_view_from_image(img_itk)\n",
        "mask_np = itk.array_view_from_image(mask_itk)\n",
        "\n",
        "print(img_files[0])\n",
        "print(\"Image shape:\", img_np.shape)\n",
        "print(\"Mask shape:\", mask_np.shape)\n",
        "\n",
        "\n",
        "fig, axes = plt.subplots(1, 2, figsize=(10, 5))\n",
        "\n",
        "axes[0].imshow(img_np)\n",
        "axes[0].set_title(\"Original Image\")\n",
        "axes[0].axis(\"off\")\n",
        "\n",
        "axes[1].imshow(mask_np, cmap=\"gray\")\n",
        "axes[1].set_title(\"Image + Mask Overlay\")\n",
        "axes[1].axis(\"off\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "J52ar28LJr2D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#%% Image Analysis\n",
        "\n",
        "colors = ['red', 'green', 'blue']\n",
        "\n",
        "for i, color in enumerate(colors):\n",
        "    plt.figure(figsize=(8, 5))\n",
        "    plt.hist(img_np[:, :, i].flatten(), bins=256, color=color, alpha=0.5, label=f\"{color} channel\")\n",
        "    plt.title(\"Histogram per Channel\")\n",
        "    plt.xlabel(\"Pixel intensity\")\n",
        "    plt.ylabel(\"Frequency\")\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "plt.figure(figsize=(6, 4))\n",
        "plt.hist(mask_np.flatten(), bins=256, color='gray')\n",
        "plt.title(\"Histogram of Mask\")\n",
        "plt.xlabel(\"Pixel intensity\")\n",
        "plt.ylabel(\"Frequency\")\n",
        "plt.show()\n",
        "\n",
        "\n",
        "for i, color in enumerate(colors):\n",
        "    channel_vals = img_np[:, :, i][mask_np > 127]\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.hist(channel_vals.flatten(), bins=256, color=color, alpha=0.5, label=f\"{color} channel\")\n",
        "    plt.title(\"Histogram of Image Pixels (within mask)\")\n",
        "    plt.xlabel(\"Pixel intensity\")\n",
        "    plt.ylabel(\"Frequency\")\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "for i, color in enumerate(colors):\n",
        "    channel_vals = img_np[:, :, i][mask_np < 128]\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.hist(channel_vals.flatten(), bins=256, color=color, alpha=0.5, label=f\"{color} channel\")\n",
        "    plt.title(\"Histogram of Image Pixels (outside mask)\")\n",
        "    plt.xlabel(\"Pixel intensity\")\n",
        "    plt.ylabel(\"Frequency\")\n",
        "    plt.legend()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "qqr-pEITJs-f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#%% Training Loop\n",
        "\n",
        "import os\n",
        "from pathlib import Path\n",
        "import cv2\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "from monai.networks.nets import UNet\n",
        "from monai.losses import DiceLoss\n",
        "\n",
        "\n",
        "# Model parameters\n",
        "IMG_SIZE = 512\n",
        "BATCH_SIZE = 5\n",
        "EPOCHS = 1000\n",
        "LR = 1e-2\n",
        "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "img_dir = Path(\"data/train/train\")\n",
        "mask_dir = Path(\"data/masks/train\")\n",
        "img_files = sorted(list(img_dir.glob(\"*.jpg\")))\n",
        "mask_files = sorted(list(mask_dir.glob(\"*.png\")))\n",
        "\n",
        "val_img_dir = Path(\"data/val/val\")\n",
        "val_mask_dir = Path(\"data/masks/val\")\n",
        "val_img_files = sorted(list(val_img_dir.glob(\"*.jpg\")))\n",
        "val_mask_files = sorted(list(val_mask_dir.glob(\"*.png\")))\n",
        "\n",
        "# Dataset\n",
        "class CellDataset(Dataset):\n",
        "    def __init__(self, img_files, mask_files, img_size=IMG_SIZE):\n",
        "        self.img_files = img_files\n",
        "        self.mask_files = mask_files\n",
        "        self.img_size = img_size\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.img_files)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img = cv2.imread(str(self.img_files[idx]))\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "        mask = cv2.imread(str(self.mask_files[idx]), cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "        img = cv2.resize(img, (self.img_size, self.img_size)).astype(np.float32)/255.0\n",
        "        mask = cv2.resize(mask, (self.img_size, self.img_size), interpolation=cv2.INTER_NEAREST)\n",
        "        mask = (mask > 127).astype(np.float32)\n",
        "\n",
        "        img = np.transpose(img, (2,0,1))\n",
        "        mask = mask[np.newaxis, ...]\n",
        "\n",
        "        mask_encode = np.zeros((2, *mask.shape[1:]), dtype=np.float32)\n",
        "        mask_encode[0] = 1 - mask\n",
        "        mask_encode[1] = mask\n",
        "\n",
        "        return torch.tensor(img), torch.tensor(mask_encode)\n",
        "\n",
        "train_dataset = CellDataset(img_files, mask_files)\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "\n",
        "val_dataset = CellDataset(val_img_files, val_mask_files)\n",
        "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
        "\n",
        "# Model\n",
        "model = UNet(\n",
        "    spatial_dims=2,\n",
        "    in_channels=3,\n",
        "    out_channels=2,\n",
        "    channels=(16,32,64,128,256),\n",
        "    strides=(2,2,2,2),\n",
        "    num_res_units=2,\n",
        "    act='leakyrelu',\n",
        "    dropout=0.5,\n",
        ").to(DEVICE)\n",
        "\n",
        "loss_fn = DiceLoss(softmax=True)\n",
        "optimizer = optim.Adam(model.parameters(), lr=LR)\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=(1/(10**0.5)))\n",
        "\n",
        "best_val_dice = 1.0\n",
        "patience = 50\n",
        "trigger_times = 0\n",
        "\n",
        "# Train loop\n",
        "for epoch in range(EPOCHS):\n",
        "    model.train()\n",
        "    epoch_loss = 0\n",
        "    for imgs, masks in train_loader:\n",
        "        imgs, masks = imgs.to(DEVICE), masks.to(DEVICE)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(imgs)\n",
        "        loss = loss_fn(outputs, masks)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        epoch_loss += loss.item()\n",
        "    epoch_loss = epoch_loss / len(train_loader)\n",
        "\n",
        "    # Validation\n",
        "    model.eval()\n",
        "    val_dice_total = 0\n",
        "    with torch.no_grad():\n",
        "        for imgs, masks in val_loader:\n",
        "            imgs, masks = imgs.to(DEVICE), masks.to(DEVICE)\n",
        "            outputs = model(imgs)\n",
        "            loss = loss_fn(outputs, masks)\n",
        "            val_dice_total += loss.item()\n",
        "    val_dice = val_dice_total / len(val_loader)\n",
        "\n",
        "    # Early stopping\n",
        "    if val_dice < best_val_dice:\n",
        "        best_val_dice = val_dice\n",
        "        trigger_times = 0\n",
        "        torch.save(model.state_dict(), \"best_unet_rgb_cells.pth\")\n",
        "    else:\n",
        "        trigger_times += 1\n",
        "        if trigger_times >= patience:\n",
        "            print(f\"Early stopping at epoch {epoch+1}\")\n",
        "            break\n",
        "\n",
        "    if (epoch+1)%50==0:\n",
        "        scheduler.step()\n",
        "\n",
        "    # Print\n",
        "    print(f\"Epoch {epoch+1}/{EPOCHS} | Train Loss: {epoch_loss:.4f} | Val Loss: {val_dice:.4f} | LR: {scheduler.get_last_lr()[0]:.6f}\")\n",
        "\n",
        "    if (epoch+1) % 10 == 0:\n",
        "        pred_bin = torch.argmax(torch.softmax(outputs, dim=1), dim=1)[0]\n",
        "        plt.figure(figsize=(12,6))\n",
        "        plt.subplot(1,2,1)\n",
        "        plt.title(\"Mask\")\n",
        "        plt.imshow(masks[0,0].cpu(), cmap='gray')\n",
        "        plt.subplot(1,2,2)\n",
        "        plt.title(\"Predicted\")\n",
        "        plt.imshow(pred_bin, cmap='gray')\n",
        "        plt.show(block=False)\n",
        "        plt.pause(0.001)\n",
        "        plt.close()"
      ],
      "metadata": {
        "id": "iWs2wzKMJuH7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#%% Testing loop\n",
        "\n",
        "def dice_score(pred, target, eps=1e-6):\n",
        "    pred = pred.float()\n",
        "    intersection = (pred * target).sum(dim=(1,2,3))\n",
        "    union = pred.sum(dim=(1,2,3)) + target.sum(dim=(1,2,3))\n",
        "    return ((2 * intersection + eps) / (union + eps)).mean().item()\n",
        "\n",
        "img_dir = Path(\"data/train/train\")\n",
        "mask_dir = Path(\"data/masks/train\")\n",
        "img_files = sorted(list(img_dir.glob(\"*.jpg\")))\n",
        "mask_files = sorted(list(mask_dir.glob(\"*.png\")))\n",
        "\n",
        "train_dataset = CellDataset(img_files, mask_files)\n",
        "train_loader = DataLoader(train_dataset, batch_size=3, shuffle=False)\n",
        "\n",
        "all_dice = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for idx, (imgs, masks) in enumerate(train_loader):\n",
        "        imgs, masks = imgs.to(DEVICE), masks.to(DEVICE)\n",
        "        outputs = torch.sigmoid(model(imgs))\n",
        "        pred_bin = (outputs > 0.5).float()\n",
        "        dice = dice_score(pred_bin, masks)\n",
        "        all_dice.append(dice)\n",
        "\n",
        "\n",
        "# Report\n",
        "mean_dice = np.mean(all_dice)\n",
        "print(f\"Train set Dice score: {mean_dice:.4f}\")\n",
        "\n",
        "\n",
        "img_dir = Path(\"data/val/val\")\n",
        "mask_dir = Path(\"data/masks/val\")\n",
        "img_files = sorted(list(img_dir.glob(\"*.jpg\")))\n",
        "mask_files = sorted(list(mask_dir.glob(\"*.png\")))\n",
        "\n",
        "val_dataset = CellDataset(img_files, mask_files)\n",
        "val_loader = DataLoader(val_dataset, batch_size=3, shuffle=False)\n",
        "\n",
        "all_dice = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for idx, (imgs, masks) in enumerate(val_loader):\n",
        "        imgs, masks = imgs.to(DEVICE), masks.to(DEVICE)\n",
        "        outputs = torch.sigmoid(model(imgs))\n",
        "        pred_bin = (outputs > 0.5).float()\n",
        "        dice = dice_score(pred_bin, masks)\n",
        "        all_dice.append(dice)\n",
        "\n",
        "\n",
        "# Report\n",
        "mean_dice = np.mean(all_dice)\n",
        "print(f\"Validation set Dice score: {mean_dice:.4f}\")\n",
        "\n",
        "\n",
        "img_dir = Path(\"data/test/test\")\n",
        "mask_dir = Path(\"data/masks/test\")\n",
        "img_files = sorted(list(img_dir.glob(\"*.jpg\")))\n",
        "mask_files = sorted(list(mask_dir.glob(\"*.png\")))\n",
        "\n",
        "test_dataset = CellDataset(img_files, mask_files)\n",
        "test_loader = DataLoader(test_dataset, batch_size=3, shuffle=False)\n",
        "\n",
        "all_dice = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for idx, (imgs, masks) in enumerate(test_loader):\n",
        "        imgs, masks = imgs.to(DEVICE), masks.to(DEVICE)\n",
        "        outputs = torch.sigmoid(model(imgs))\n",
        "        pred_bin = (outputs > 0.5).float()\n",
        "        dice = dice_score(pred_bin, masks)\n",
        "        all_dice.append(dice)\n",
        "\n",
        "# Report\n",
        "mean_dice = np.mean(all_dice)\n",
        "print(f\"Test set Dice score: {mean_dice:.4f}\")"
      ],
      "metadata": {
        "id": "c2dDnLsMJ0VM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}