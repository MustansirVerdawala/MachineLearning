{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O7Hoh2BfJ43d"
      },
      "outputs": [],
      "source": [
        "# =============================================================== #\n",
        "#                    3D Spleen Segmenatation                      #\n",
        "#                      Mustansir Verdawala                        #\n",
        "# =============================================================== #"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#%% Install necessary libraries\n",
        "\n",
        "!pip install \"monai[all]\" nibabel SimpleITK torch torchvision torchaudio matplotlib numpy scikit-learn tqdm huggingface_hub"
      ],
      "metadata": {
        "id": "OL1aXDhpKApD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#%% Downloading dataset\n",
        "\n",
        "from datasets import load_dataset\n",
        "\n",
        "# Load the dataset\n",
        "ds = load_dataset(\"Angelou0516/msd-spleen\")\n",
        "\n",
        "from huggingface_hub import snapshot_download\n",
        "import nibabel as nib\n",
        "import os\n",
        "\n",
        "# Download the full dataset\n",
        "local_path = snapshot_download(\n",
        "    repo_id=\"Angelou0516/msd-spleen\",\n",
        "    local_dir=\"/content/msd-spleen\",\n",
        "    repo_type=\"dataset\"\n",
        ")"
      ],
      "metadata": {
        "id": "5fd4w3hpKCUn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#%% Image Analysis\n",
        "\n",
        "import nibabel as nib\n",
        "import os\n",
        "import random\n",
        "import shutil\n",
        "from glob import glob\n",
        "\n",
        "root_dir = \"/content/msd-spleen\"\n",
        "img_dir = os.path.join(root_dir, \"imagesTr\")\n",
        "lbl_dir = os.path.join(root_dir, \"labelsTr\")\n",
        "\n",
        "split_root = \"/content/msd-spleen_split\"\n",
        "splits = [\"train\", \"val\", \"test\"]\n",
        "\n",
        "for s in splits:\n",
        "    os.makedirs(os.path.join(split_root, s, \"images\"), exist_ok=True)\n",
        "    os.makedirs(os.path.join(split_root, s, \"labels\"), exist_ok=True)\n",
        "\n",
        "images = sorted(glob(os.path.join(img_dir, \"*.nii.gz\")))\n",
        "labels = sorted(glob(os.path.join(lbl_dir, \"*.nii.gz\")))\n",
        "\n",
        "random.seed(42)  # set for reproducibility\n",
        "indices = list(range(len(images)))\n",
        "random.shuffle(indices)\n",
        "\n",
        "train_idx = indices[:20]\n",
        "val_idx = indices[20:30]\n",
        "test_idx = indices[30:]\n",
        "\n",
        "def copy_split(indices, split_name):\n",
        "    for i in indices:\n",
        "        img_file = images[i]\n",
        "        lbl_file = labels[i]\n",
        "        shutil.copy(img_file, os.path.join(split_root, split_name, \"images\"))\n",
        "        shutil.copy(lbl_file, os.path.join(split_root, split_name, \"labels\"))\n",
        "\n",
        "copy_split(train_idx, \"train\")\n",
        "copy_split(val_idx, \"val\")\n",
        "copy_split(test_idx, \"test\")\n",
        "\n",
        "print(f\"Split complete. Files saved under: {split_root}\")\n",
        "for s in splits:\n",
        "    n_imgs = len(os.listdir(os.path.join(split_root, s, \"images\")))\n",
        "    print(f\"{s.capitalize()}: {n_imgs} images\")"
      ],
      "metadata": {
        "id": "aNhtLi-XKD2H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nibabel as nib\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "from glob import glob\n",
        "\n",
        "local_path = \"/content/msd-spleen\"\n",
        "\n",
        "image_files = sorted(glob(os.path.join(local_path, \"imagesTr\", \"*.nii.gz\")))\n",
        "label_files = sorted(glob(os.path.join(local_path, \"labelsTr\", \"*.nii.gz\")))\n",
        "\n",
        "idx = 18\n",
        "image_path = image_files[idx]\n",
        "mask_path = label_files[idx]\n",
        "\n",
        "image = nib.load(image_path)\n",
        "mask = nib.load(mask_path)\n",
        "\n",
        "image_data = image.get_fdata()\n",
        "mask_data = mask.get_fdata()\n",
        "\n",
        "print(f\"Loaded: {os.path.basename(image_path)}\")\n",
        "print(f\"Image shape: {image_data.shape}\")\n",
        "print(f\"Mask shape: {mask_data.shape}\")\n",
        "\n",
        "slice_idx = image_data.shape[2] // 2\n",
        "\n",
        "plt.figure(figsize=(10,5))\n",
        "\n",
        "# CT image\n",
        "plt.subplot(1,2,1)\n",
        "plt.imshow(image_data[:, :, slice_idx], cmap='gray')\n",
        "plt.title(f\"CT Slice {slice_idx}\")\n",
        "plt.axis('off')\n",
        "\n",
        "# Mask overlay\n",
        "plt.subplot(1,2,2)\n",
        "plt.imshow(mask_data[:, :, slice_idx], cmap='gray', alpha=1)\n",
        "plt.title(\"Mask\")\n",
        "plt.axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "img_flat = image_data.flatten()\n",
        "mask_flat = mask_data.flatten()\n",
        "\n",
        "spleen_voxels = image_data[mask_data > 0]\n",
        "\n",
        "plt.figure(figsize=(10,5))\n",
        "plt.hist(img_flat, bins=100, color='gray', alpha=0.6, label='All Voxels')\n",
        "plt.xlabel(\"Intensity\")\n",
        "plt.ylabel(\"Voxel Count\")\n",
        "plt.legend()\n",
        "plt.title(\"Voxel Intensity Distribution\")\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(10,5))\n",
        "plt.hist(spleen_voxels, bins=100, color='red', alpha=0.6, label='Spleen Region')\n",
        "plt.xlabel(\"Intensity\")\n",
        "plt.ylabel(\"Voxel Count\")\n",
        "plt.legend()\n",
        "plt.title(\"Voxel Intensity Distribution\")\n",
        "plt.show()\n",
        "\n",
        "print(np.unique(mask_data))"
      ],
      "metadata": {
        "id": "-EVTSW_SKFHK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import nibabel as nib\n",
        "from glob import glob\n",
        "\n",
        "image_dir = \"/content/msd-spleen/imagesTr\"\n",
        "label_dir = \"/content/msd-spleen/labelsTr\"\n",
        "\n",
        "image_files = sorted(glob(os.path.join(image_dir, \"*.nii.gz\")))\n",
        "label_files = sorted(glob(os.path.join(label_dir, \"*.nii.gz\")))\n",
        "\n",
        "print(\"Image Shapes\")\n",
        "for f in image_files:\n",
        "    img = nib.load(f)\n",
        "    print(f\"{os.path.basename(f)}: {img.get_fdata().shape}\")"
      ],
      "metadata": {
        "id": "4nXunyZuKHRE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "import nibabel as nib\n",
        "from glob import glob\n",
        "from scipy.ndimage import binary_closing, generate_binary_structure\n",
        "from monai.data import Dataset, DataLoader\n",
        "from monai.networks.nets import UNet\n",
        "from monai.losses import DiceLoss\n",
        "from skimage.transform import resize\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Device set: {DEVICE}\")\n",
        "\n",
        "root_dir = \"/content/msd-spleen_split\"\n",
        "train_images = sorted(glob(os.path.join(root_dir, \"train/images/*.nii.gz\")))\n",
        "train_labels = sorted(glob(os.path.join(root_dir, \"train/labels/*.nii.gz\")))\n",
        "val_images = sorted(glob(os.path.join(root_dir, \"val/images/*.nii.gz\")))\n",
        "val_labels = sorted(glob(os.path.join(root_dir, \"val/labels/*.nii.gz\")))\n",
        "\n",
        "PATCH_DEPTH = 128\n",
        "IMG_SIZE = 256\n",
        "\n",
        "# Preprocessing\n",
        "def preprocess(img_path, lbl_path, hu_min=-190, hu_max=300, closing_radius=3):\n",
        "    img = nib.load(img_path).get_fdata()\n",
        "    lbl = nib.load(lbl_path).get_fdata()\n",
        "    lbl[img < hu_min] = 0\n",
        "    lbl[img > hu_max] = 0\n",
        "    struct = generate_binary_structure(3, 1)\n",
        "    struct = np.pad(struct, closing_radius-1, mode='constant', constant_values=0)\n",
        "    lbl_closed = binary_closing(lbl, structure=struct).astype(np.uint8)\n",
        "    img = np.clip(img, -1024, 1023)\n",
        "    img = (img + 1024) / 2047\n",
        "    return img.astype(np.float32), lbl_closed\n",
        "\n",
        "def generate_patches(img, lbl, patch_depth=PATCH_DEPTH):\n",
        "    patches = []\n",
        "    z_slices = img.shape[2]\n",
        "    start = 0\n",
        "    while start < z_slices:\n",
        "        end = start + patch_depth\n",
        "        if end <= z_slices:\n",
        "            patch_img = img[:, :, start:end]\n",
        "            patch_lbl = lbl[:, :, start:end]\n",
        "        else:\n",
        "            patch_img = img[:, :, -patch_depth:]\n",
        "            patch_lbl = lbl[:, :, -patch_depth:]\n",
        "        # Resize to 256x256x64\n",
        "        patch_img = resize(\n",
        "            patch_img, (IMG_SIZE, IMG_SIZE, patch_depth),\n",
        "            order=1, preserve_range=True, anti_aliasing=True\n",
        "        ).astype(np.float32)\n",
        "        patch_lbl = resize(\n",
        "            patch_lbl, (IMG_SIZE, IMG_SIZE, patch_depth),\n",
        "            order=0, preserve_range=True, anti_aliasing=False\n",
        "        ).astype(np.uint8)\n",
        "        patches.append((patch_img, patch_lbl))\n",
        "        start += patch_depth\n",
        "    return patches\n",
        "\n",
        "# Dataset\n",
        "class SpleenPatchDataset(Dataset):\n",
        "    def __init__(self, img_files, lbl_files):\n",
        "        self.patches = []\n",
        "        for i, l in zip(img_files, lbl_files):\n",
        "            img, lbl = preprocess(i, l)\n",
        "            self.patches.extend(generate_patches(img, lbl))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.patches)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img, lbl = self.patches[idx]\n",
        "        img = img[np.newaxis, ...]\n",
        "        lbl = lbl[np.newaxis, ...]\n",
        "        # One-hot labels\n",
        "        lbl_onehot = np.zeros((2, *lbl.shape[1:]), dtype=np.float32)\n",
        "        lbl_onehot[0] = 1 - lbl\n",
        "        lbl_onehot[1] = lbl\n",
        "        return torch.tensor(img, dtype=torch.float32), torch.tensor(lbl_onehot, dtype=torch.float32)\n",
        "\n",
        "train_ds = SpleenPatchDataset(train_images, train_labels)\n",
        "val_ds = SpleenPatchDataset(val_images, val_labels)\n",
        "train_loader = DataLoader(train_ds, batch_size=2, shuffle=True)\n",
        "val_loader = DataLoader(val_ds, batch_size=1, shuffle=True)\n",
        "\n",
        "# Model\n",
        "model = UNet(\n",
        "    spatial_dims=3,\n",
        "    in_channels=1,\n",
        "    out_channels=2,\n",
        "    channels=(8, 16, 32, 64),\n",
        "    strides=(2,2,2),\n",
        "    num_res_units=2,\n",
        "    dropout=0.5,\n",
        "    act=\"leakyrelu\",\n",
        "    kernel_size=3\n",
        ").to(DEVICE)\n",
        "\n",
        "loss_fn = DiceLoss(softmax=True)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-2)\n",
        "scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[100, 200, 350], gamma=0.1)\n",
        "\n",
        "# Training loop with plotting\n",
        "EPOCHS = 1000\n",
        "best_val_loss = 1.0\n",
        "patience = 30\n",
        "trigger_times = 0\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    # Train\n",
        "    model.train()\n",
        "    train_loss = 0\n",
        "    for imgs, masks in train_loader:\n",
        "        imgs, masks = imgs.to(DEVICE), masks.to(DEVICE)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(imgs)\n",
        "        loss = loss_fn(outputs, masks)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        train_loss += loss.item()\n",
        "    train_loss /= len(train_loader)\n",
        "\n",
        "    # Validation\n",
        "    model.eval()\n",
        "    val_loss_total = 0\n",
        "    valid_patches = 0\n",
        "    with torch.no_grad():\n",
        "        for i, (imgs, masks) in enumerate(val_loader):\n",
        "            imgs, masks = imgs.to(DEVICE), masks.to(DEVICE)\n",
        "            if masks[0, 1].sum() == 0:\n",
        "                continue  # skip empty patch\n",
        "            outputs = model(imgs)\n",
        "\n",
        "            loss = loss_fn(outputs, masks)\n",
        "            val_loss_total += loss.item()\n",
        "            valid_patches += 1\n",
        "\n",
        "            # Plot first patch every 10 epochs\n",
        "            if epoch % 10 == 0 and i == 0:\n",
        "                pred_mask = torch.argmax(torch.softmax(outputs, dim=1), dim=1).cpu().numpy()[0]\n",
        "                true_mask = torch.argmax(masks, dim=1).cpu().numpy()[0]\n",
        "                slice_idx = PATCH_DEPTH // 2\n",
        "                plt.figure(figsize=(10,5))\n",
        "                plt.subplot(1,2,1)\n",
        "                plt.imshow(true_mask[:, :, slice_idx], cmap='gray')\n",
        "                plt.title(\"Ground Truth\")\n",
        "                plt.subplot(1,2,2)\n",
        "                plt.imshow(pred_mask[:, :, slice_idx], cmap='gray')\n",
        "                plt.title(f\"Prediction Epoch {epoch+1}\")\n",
        "                plt.show()\n",
        "\n",
        "    val_loss = val_loss_total / valid_patches\n",
        "\n",
        "    # Early stopping\n",
        "    if val_loss < best_val_loss:\n",
        "        best_val_loss = val_loss\n",
        "        trigger_times = 0\n",
        "        torch.save(model.state_dict(), \"best_patch_3dunet_spleen.pth\")\n",
        "    else:\n",
        "        trigger_times += 1\n",
        "        if trigger_times >= patience:\n",
        "            print(f\"Early stopping at epoch {epoch+1}\")\n",
        "            break\n",
        "\n",
        "    scheduler.step()\n",
        "    print(f\"Epoch {epoch+1}/{EPOCHS} | Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f} | LR: {scheduler.get_last_lr()[0]:.6e}\")\n"
      ],
      "metadata": {
        "id": "Gx903bFfKIL8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "THRESH = 0.5\n",
        "\n",
        "def dice_coefficient_manual(pred, target, eps=1e-8):\n",
        "    intersection = torch.sum(pred * target).item()\n",
        "    union = torch.sum(pred).item() + torch.sum(target).item()\n",
        "    return (2. * intersection + eps) / (union + eps)\n",
        "\n",
        "def jaccard_index_manual(pred, target, eps=1e-8):\n",
        "    intersection = torch.sum(pred * target).item()\n",
        "    union = torch.sum(pred).item() + torch.sum(target).item() - intersection\n",
        "    return (intersection + eps) / (union + eps)\n",
        "\n",
        "@torch.no_grad()\n",
        "def evaluate_full_scan_torch(loader, model, name=\"Dataset\"):\n",
        "    model.eval()\n",
        "    scan_dices = []\n",
        "    scan_jaccs = []\n",
        "\n",
        "    for scan_idx, (imgs, masks) in enumerate(tqdm(loader, desc=f\"Evaluating {name}\")):\n",
        "        imgs, masks = imgs.to(device), masks.to(device)\n",
        "        B, C, H, W, D = imgs.shape\n",
        "        assert B == 1, \"Loader should load one scan at a time for full evaluation\"\n",
        "\n",
        "        prob_accum = torch.zeros((2, H, W, D), device=device)\n",
        "        count_accum = torch.zeros((H, W, D), device=device)\n",
        "\n",
        "        outputs = model(imgs)  # shape: 1x2xHxWxD\n",
        "        probs = torch.softmax(outputs, dim=1)[0]  # 2xHxWxD\n",
        "        prob_accum += probs\n",
        "        count_accum += 1.0\n",
        "\n",
        "        prob_avg = prob_accum / torch.clamp(count_accum, min=1.0)\n",
        "\n",
        "        pred_bin = (prob_avg[1] >= THRESH).float()\n",
        "        true_bin = masks[0, 1].float()\n",
        "\n",
        "        dice_val = dice_coefficient_manual(pred_bin, true_bin)\n",
        "        jacc_val = jaccard_index_manual(pred_bin, true_bin)\n",
        "\n",
        "        scan_dices.append(dice_val)\n",
        "        scan_jaccs.append(jacc_val)\n",
        "        print(f\"\\nScan {scan_idx} | Dice: {dice_val:.4f} | Jaccard: {jacc_val:.4f}\")\n",
        "\n",
        "    mean_dice = np.mean(scan_dices)\n",
        "    mean_jacc = np.mean(scan_jaccs)\n",
        "    print(f\"\\n{name} Overall | Mean Dice: {mean_dice:.4f} | Mean Jaccard: {mean_jacc:.4f}\")\n",
        "    print(\"-\" * 40)\n",
        "    return mean_dice, mean_jacc\n",
        "\n",
        "test_images = sorted(glob(os.path.join(root_dir, \"test/images/*.nii.gz\")))\n",
        "test_labels = sorted(glob(os.path.join(root_dir, \"test/labels/*.nii.gz\")))\n",
        "\n",
        "train_loader_full = DataLoader(train_ds, batch_size=1, shuffle=False)\n",
        "val_loader_full = DataLoader(val_ds, batch_size=1, shuffle=False)\n",
        "test_loader_full = DataLoader(SpleenPatchDataset(test_images, test_labels), batch_size=1, shuffle=False)\n",
        "\n",
        "train_dice, train_jacc = evaluate_full_scan_torch(train_loader_full, model, name=\"Train Set\")\n",
        "val_dice, val_jacc = evaluate_full_scan_torch(val_loader_full, model, name=\"Validation Set\")\n",
        "test_dice, test_jacc = evaluate_full_scan_torch(test_loader_full, model, name=\"Test Set\")"
      ],
      "metadata": {
        "id": "n7hjZNNsKJba"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fXwh3_3YKM4g"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}